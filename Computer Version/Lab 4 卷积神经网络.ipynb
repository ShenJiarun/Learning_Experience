{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81eeda52-acd3-4d1d-8292-01e54f0b42f5",
   "metadata": {},
   "source": [
    "### 1. 卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b30723d-3850-475d-a18b-bc2701c136b4",
   "metadata": {},
   "source": [
    "# 图像卷积\n",
    "上节我们解析了卷积层的原理，现在我们看看它的实际应用。由于卷积神经网络的设计是用于探索图像数据，本节我们将以图像为例。\n",
    "\n",
    "## 互相关运算\n",
    "\n",
    "严格来说，卷积层是个错误的叫法，因为它所表达的运算其实是*互相关运算*（cross-correlation），而不是卷积运算。\n",
    "根据中的描述，在卷积层中，输入张量和核张量通过**互相关运算**产生输出张量。\n",
    "\n",
    "首先，我们暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示。在下图中，输入是高度为$3$、宽度为$3$的二维张量（即形状为$3 \\times 3$）。卷积核的高度和宽度都是$2$，而卷积核窗口（或卷积窗口）的形状由内核的高度和宽度决定（即$2 \\times 2$）。\n",
    "\n",
    "![二维互相关运算。阴影部分是第一个输出元素，以及用于计算输出的输入张量元素和核张量元素：$0\\times0+1\\times1+3\\times2+4\\times3=19$.](http://d2l.ai/_images/correlation.svg)\n",
    "\n",
    "在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。\n",
    "当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。\n",
    "在如上例子中，输出张量的四个元素由二维互相关运算得到，这个输出高度为$2$、宽度为$2$，如下所示：\n",
    "\n",
    "$$\n",
    "0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n",
    "1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n",
    "3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n",
    "4\\times0+5\\times1+7\\times2+8\\times3=43.\n",
    "$$\n",
    "\n",
    "注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1，\n",
    "而卷积核只与图像中每个大小完全适合的位置进行互相关运算。\n",
    "所以，输出大小等于输入大小$n_h \\times n_w$减去卷积核大小$k_h \\times k_w$，即：\n",
    "\n",
    "$$(n_h-k_h+1) \\times (n_w-k_w+1).$$\n",
    "\n",
    "这是因为我们需要足够的空间在图像上“移动”卷积核。稍后，我们将看到如何通过在图像边界周围填充零来保证有足够的空间移动卷积核，从而保持输出大小不变。\n",
    "接下来，我们在`corr2d`函数中实现如上过程，该函数接受输入张量`X`和卷积核张量`K`，并返回输出张量`Y`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ecb73c-699b-476b-9b87-bfb2cd422cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    X: 代表输入的图像矩阵\n",
    "    K: 卷积核\n",
    "    暂不考虑padding的情况下，输出的矩阵的大小是：(n_h-k_h+1) * (n_w-k_w+1)\n",
    "    \"\"\"\n",
    "    n_h, n_w = X.shape\n",
    "    k_h, k_w = K.shape\n",
    "    out_h = n_h - k_h + 1\n",
    "    out_w = n_w - k_w + 1\n",
    "    out = torch.zeros(size=(out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            out[i, j] = (X[i:i+k_h, j:j+k_w] * K).sum()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a8ff90-a858-4afa-aa6b-aa0cb7c291fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e16565-63b5-4d4b-8301-d312818f9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_official(X, K):  #@save\n",
    "    \"\"\"计算二维互相关运算\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee326b45-ce71-4322-8936-97e854224ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "corr2d_official(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68bd5bc2-bc0b-4728-93e5-fc64eef08684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X, K) == corr2d_official(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8f7b9f-c55e-4ea1-8ea1-1b8c5f188986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1],dtype=float).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff8fb0-b9b6-4235-b0ad-1bb38cfe4902",
   "metadata": {},
   "source": [
    "## 卷积层\n",
    "\n",
    "卷积层对输入和卷积核权重进行互相关运算，并在添加标量偏置之后产生输出。\n",
    "所以，卷积层中的两个被训练的参数是卷积核权重和标量偏置。\n",
    "就像我们之前随机初始化全连接层一样，在训练基于卷积层的模型时，我们也随机初始化卷积核权重。\n",
    "\n",
    "基于上面定义的`corr2d`函数**实现二维卷积层**。在`__init__`构造函数中，将`weight`和`bias`声明为两个模型参数。前向传播函数调用`corr2d`函数并添加偏置。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc7d2d-5545-4007-90f4-2a5bcf4f7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        \"\"\"\n",
    "        kernel_size: 一个元组或者list(kernel的长, kernel的高)\n",
    "        \"\"\"\n",
    "        # self.weight = nn.Parameter(torch.randn(size=kernel_size))\n",
    "        self.weight = nn.Parameter(torch.rand(size=kernel_size))\n",
    "        # self.bias = nn.Parameter(torch.randn(size=(1,)))\n",
    "        self.bias = nn.Parameter(torch.zeros(size=(1,)))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return corr2d(X, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f211b50-01f7-4a8b-88c4-46213dece0f2",
   "metadata": {},
   "source": [
    "高度和宽度分别为$h$和$w$的卷积核可以被称为$h \\times w$卷积或$h \\times w$卷积核。\n",
    "我们也将带有$h \\times w$卷积核的卷积层称为$h \\times w$卷积层。\n",
    "\n",
    "## 图像中目标的边缘检测\n",
    "\n",
    "如下是**卷积层的一个简单应用：**\n",
    "通过找到像素变化的位置，来**检测图像中不同颜色的边缘**。\n",
    "首先，我们构造一个$6\\times 8$像素的黑白图像。中间四列为黑色（$0$），其余像素为白色（$1$）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f04dc3f-bc7e-488a-8fe8-104bc802fda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df88eb8-e70f-4fc3-ac6e-2f6512ae379c",
   "metadata": {},
   "source": [
    "接下来，我们构造一个高度为$1$、宽度为$2$的卷积核`K`。当进行互相关运算时，如果水平相邻的两元素相同，则输出为零，否则输出为非零。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ab3ca1f-26f0-48e2-95d0-bb103c29f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e8664-9db8-4665-8f24-4e2b898c0bd9",
   "metadata": {},
   "source": [
    "现在，我们对参数`X`（输入）和`K`（卷积核）执行互相关运算。\n",
    "如下所示，**输出`Y`中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘**，其他情况的输出为$0$。(也就是说相同颜色的部分使用该卷积核时输出为0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8af9a1a6-38b9-4e81-895e-88de20064f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0f205-aee1-4634-b9e6-62109c3d53e9",
   "metadata": {},
   "source": [
    "现在我们将输入的二维图像转置，再进行如上的互相关运算。\n",
    "其输出如下，之前检测到的垂直边缘消失了。\n",
    "不出所料，这个**卷积核`K`只可以检测垂直边缘**，无法检测水平边缘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c04b80b4-5baf-425c-9e2c-9325f5627b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_transpose = corr2d(X.T, K)\n",
    "Y_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3a9cb-3f45-4f75-904e-74d704742d9f",
   "metadata": {},
   "source": [
    "## 学习卷积核\n",
    "\n",
    "如果我们只需寻找黑白边缘，那么以上`[1, -1]`的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计滤波器。那么我们是否可以[**学习由`X`生成`Y`的卷积核**]呢？\n",
    "\n",
    "现在让我们看看是否可以通过仅查看“输入-输出”对来学习由`X`生成`Y`的卷积核。\n",
    "我们先构造一个卷积层，并将其卷积核初始化为随机张量。接下来，在每次迭代中，我们比较`Y`与卷积层输出的平方误差，然后计算梯度来更新卷积核。为了简单起见，我们在此使用内置的二维卷积层，并忽略偏置。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6391e59-031d-4038-9849-8e85049aa6d4",
   "metadata": {},
   "source": [
    "使用的新函数: <font color=\"green\"> `torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)` </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a37c9355-49f8-4cb2-a074-e1289cc0adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 10.007\n",
      "epoch 4, loss 2.074\n",
      "epoch 6, loss 0.510\n",
      "epoch 8, loss 0.152\n",
      "epoch 10, loss 0.053\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
    "# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n",
    "# 其中批量大小和通道数都为1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2  # 学习率\n",
    "trainer=torch.optim.SGD(conv2d.parameters(), lr=lr)\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = loss(Y_hat, Y)\n",
    "    trainer.zero_grad()\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i+1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2f848a3-388e-4a46-af66-d735501dd430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0071, -0.9628]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbe9d68d-c675-4a92-909c-30faffdfc4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8., 1., 6., 1., 6., 2., 9., 3.],\n",
       "          [7., 8., 8., 9., 6., 7., 3., 8.],\n",
       "          [4., 9., 3., 3., 5., 6., 4., 0.],\n",
       "          [6., 0., 4., 9., 6., 2., 4., 3.],\n",
       "          [6., 9., 1., 2., 8., 0., 5., 0.],\n",
       "          [0., 5., 8., 2., 4., 2., 1., 2.]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randint(low=0, high=10, size=(6,8)).float().reshape((1, 1, 6, 8))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "275d6173-c044-4c2e-afa4-58d9fd94107f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (5) must match the size of tensor b (6) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m     11\u001b[0m     Y_hat \u001b[38;5;241m=\u001b[39m conv2d(X)\n\u001b[0;32m---> 12\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m     l\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/functional.py:3279\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3277\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3279\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (6) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(2, 2), bias=False)\n",
    "# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），\n",
    "# 其中批量大小和通道数都为1\n",
    "# X = torch.randint(low=0, high=10, size=(4,4)).float().reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 2e-4  # 学习率\n",
    "trainer=torch.optim.SGD(conv2d.parameters(), lr=lr)\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "for i in range(20):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = loss(Y_hat, Y)\n",
    "    trainer.zero_grad()\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i+1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e849811-bfd9-49aa-b374-60a21d03274e",
   "metadata": {},
   "source": [
    "输出尺寸的计算公式是(W−F+2P)/S+1，W是输入的边长，F是卷积核的边长，P是填充，S是步幅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31643e-0d96-4a7b-b70e-f8f31ac54b49",
   "metadata": {},
   "source": [
    "细心的读者一定会发现，我们学习到的卷积核权重非常接近我们之前定义的卷积核`K`。\n",
    "\n",
    "## 互相关和卷积\n",
    "\n",
    "回想一下我们在 :numref:`sec_why-conv`中观察到的互相关和卷积运算之间的对应关系。\n",
    "为了得到正式的*卷积*运算输出，我们需要执行 :eqref:`eq_2d-conv-discrete`中定义的严格卷积运算，而不是互相关运算。\n",
    "幸运的是，它们差别不大，我们只需水平和垂直翻转二维卷积核张量，然后对输入张量执行*互相关*运算。\n",
    "\n",
    "值得注意的是，由于卷积核是从数据中学习到的，因此无论这些层执行严格的卷积运算还是互相关运算，卷积层的输出都不会受到影响。\n",
    "为了说明这一点，假设卷积层执行*互相关*运算并学习 :numref:`fig_correlation`中的卷积核，该卷积核在这里由矩阵$\\mathbf{K}$表示。\n",
    "假设其他条件不变，当这个层执行严格的*卷积*时，学习的卷积核$\\mathbf{K}'$在水平和垂直翻转之后将与$\\mathbf{K}$相同。\n",
    "也就是说，当卷积层对 :numref:`fig_correlation`中的输入和$\\mathbf{K}'$执行严格*卷积*运算时，将得到与互相关运算 :numref:`fig_correlation`中相同的输出。\n",
    "\n",
    "为了与深度学习文献中的标准术语保持一致，我们将继续把“互相关运算”称为卷积运算，尽管严格地说，它们略有不同。\n",
    "此外，对于卷积核张量上的权重，我们称其为*元素*。\n",
    "\n",
    "## 特征映射和感受野\n",
    "\n",
    "如在 :numref:`subsec_why-conv-channels`中所述， :numref:`fig_correlation`中输出的卷积层有时被称为*特征映射*（feature map），因为它可以被视为一个输入映射到下一层的空间维度的转换器。\n",
    "在卷积神经网络中，对于某一层的任意元素$x$，其*感受野*（receptive field）是指在前向传播期间可能影响$x$计算的所有元素（来自所有先前层）。\n",
    "\n",
    "请注意，感受野可能大于输入的实际大小。让我们用 :numref:`fig_correlation`为例来解释感受野：\n",
    "给定$2 \\times 2$卷积核，阴影输出元素值$19$的感受野是输入阴影部分的四个元素。\n",
    "假设之前输出为$\\mathbf{Y}$，其大小为$2 \\times 2$，现在我们在其后附加一个卷积层，该卷积层以$\\mathbf{Y}$为输入，输出单个元素$z$。\n",
    "在这种情况下，$\\mathbf{Y}$上的$z$的感受野包括$\\mathbf{Y}$的所有四个元素，而输入的感受野包括最初所有九个输入元素。\n",
    "因此，当一个特征图中的任意元素需要检测更广区域的输入特征时，我们可以构建一个更深的网络。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 二维卷积层的核心计算是二维互相关运算。最简单的形式是，对二维输入数据和卷积核执行互相关操作，然后添加一个偏置。\n",
    "* 我们可以设计一个卷积核来检测图像的边缘。\n",
    "* 我们可以从数据中学习卷积核的参数。\n",
    "* 学习卷积核时，无论用严格卷积运算或互相关运算，卷积层的输出不会受太大影响。\n",
    "* 当需要检测输入特征中更广区域时，我们可以构建一个更深的卷积网络。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 构建一个具有对角线边缘的图像`X`。\n",
    "    1. 如果将本节中举例的卷积核`K`应用于`X`，会发生什么情况？\n",
    "    1. 如果转置`X`会发生什么？\n",
    "    1. 如果转置`K`会发生什么？\n",
    "1. 在我们创建的`Conv2D`自动求导时，有什么错误消息？\n",
    "1. 如何通过改变输入张量和卷积核张量，将互相关运算表示为矩阵乘法？\n",
    "1. 手工设计一些卷积核。\n",
    "    1. 二阶导数的核的形式是什么？\n",
    "    1. 积分的核的形式是什么？\n",
    "    1. 得到$d$次导数的最小核的大小是多少？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52972b81-0038-4c89-aad5-804459363eb8",
   "metadata": {},
   "source": [
    "# 填充和步幅\n",
    "\n",
    "在前面的例子中，输入的高度和宽度都为$3$，卷积核的高度和宽度都为$2$，生成的输出表征的维数为$2\\times2$。\n",
    "正如我们在中所概括的那样，假设输入形状为$n_h\\times n_w$，卷积核形状为$k_h\\times k_w$，那么输出形状将是$(n_h-k_h+1) \\times (n_w-k_w+1)$。\n",
    "因此，卷积的输出形状取决于输入形状和卷积核的形状。\n",
    "\n",
    "还有什么因素会影响输出的大小呢？本节我们将介绍*填充*（padding）和*步幅*（stride）。假设以下情景：\n",
    "有时，在应用了连续的卷积之后，我们最终得到的输出远小于输入大小。这是由于卷积核的宽度和高度通常大于$1$所导致的。比如，一个$240 \\times 240$像素的图像，经过$10$层$5 \\times 5$的卷积后，将减少到$200 \\times 200$像素。如此一来，原始图像的边界丢失了许多有用信息。而*填充*是解决此问题最有效的方法；\n",
    "有时，我们可能希望大幅降低图像的宽度和高度。例如，如果我们发现原始的输入分辨率十分冗余。*步幅*则可以在这类情况下提供帮助。\n",
    "\n",
    "## 填充\n",
    "\n",
    "如上所述，在应用多层卷积时，我们常常丢失边缘像素。\n",
    "由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。\n",
    "但随着我们应用许多连续卷积层，累积丢失的像素数就多了。\n",
    "解决这个问题的简单方法即为*填充*（padding）：在输入图像的边界填充元素（通常填充元素是$0$）。\n",
    "例如，在下图中，我们将$3 \\times 3$输入填充到$5 \\times 5$，那么它的输出就增加为$4 \\times 4$。阴影部分是第一个输出元素以及用于输出计算的输入和核张量元素：\n",
    "$0\\times0+0\\times1+0\\times2+0\\times3=0$。\n",
    "\n",
    "![带填充的二维互相关。](https://zh.d2l.ai/_images/conv-pad.svg)\n",
    "\n",
    "通常，如果我们添加$p_h$行填充（大约一半在顶部，一半在底部）和$p_w$列填充（左侧大约一半，右侧一半），则输出形状将为\n",
    "\n",
    "$$(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1)。$$\n",
    "\n",
    "这意味着输出的高度和宽度将分别增加$p_h$和$p_w$。\n",
    "\n",
    "在许多情况下，我们需要设置$p_h=k_h-1$和$p_w=k_w-1$，使输入和输出具有相同的高度和宽度。\n",
    "这样可以在构建网络时更容易地预测每个图层的输出形状。假设$k_h$是奇数，我们将在高度的两侧填充$p_h/2$行。\n",
    "如果$k_h$是偶数，则一种可能性是在输入顶部填充$\\lceil p_h/2\\rceil$行，在底部填充$\\lfloor p_h/2\\rfloor$行。同理，我们填充宽度的两侧。\n",
    "\n",
    "卷积神经网络中卷积核的高度和宽度通常为奇数，例如1、3、5或7。\n",
    "选择奇数的好处是，保持空间维度的同时，我们可以在顶部和底部填充相同数量的行，在左侧和右侧填充相同数量的列。\n",
    "\n",
    "此外，使用奇数的核大小和填充大小也提供了书写上的便利。对于任何二维张量`X`，当满足：\n",
    "1. 卷积核的大小是奇数；\n",
    "2. 所有边的填充行数和列数相同；\n",
    "3. 输出与输入具有相同高度和宽度\n",
    "则可以得出：输出`Y[i, j]`是通过以输入`X[i, j]`为中心，与卷积核进行互相关计算得到的。\n",
    "\n",
    "比如，在下面的例子中，我们创建一个高度和宽度为3的二维卷积层，并**在所有侧边填充1个像素**。给定高度和宽度为8的输入，则输出的高度和宽度也是8。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5bef183e-eaf8-427e-9d2f-a55d6c9755dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:]) ### 更方便我们查看使用padding之后的输出的维度,更多是为了学术目的\n",
    "\n",
    "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列，此时的参数padding=1\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 3), padding=1) ## 这里的padding是对每一条边的填充\n",
    "### 这里的kernel_size=3和kernel_size=(3, 3)是一样的\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b66b3c68-39fd-4ead-9de9-5fc8c571c940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[ 0.3019,  0.2898,  0.1491],\n",
      "          [-0.2293,  0.1742,  0.0114],\n",
      "          [ 0.0782, -0.0731, -0.1753]]]])\n"
     ]
    }
   ],
   "source": [
    "print(conv2d.weight.data.shape)\n",
    "print(conv2d.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648800d9-21cc-4dab-a37a-4a555fdc92dd",
   "metadata": {},
   "source": [
    "当卷积核的高度和宽度不同时，我们可以**填充不同的高度和宽度**，使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。\n",
    "\n",
    "请注意，此时的公式是：输出大小 = (输入大小 - 卷积核大小 + 2*填充) / 步幅 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc5a4485-ecf9-43e2-8e77-25cfd404db47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4131, -0.0380, -0.2003, -0.2571, -0.0347, -0.1386, -0.3103, -0.0803],\n",
      "        [-0.3577,  0.1633, -0.1119, -0.1323,  0.0724,  0.1019,  0.0828,  0.1626],\n",
      "        [-0.2980,  0.0632, -0.3158,  0.0499, -0.0601,  0.0759,  0.1411,  0.1912],\n",
      "        [-0.1801,  0.1626, -0.0935,  0.1746, -0.0518, -0.0751, -0.0590,  0.0876],\n",
      "        [-0.2075,  0.1254,  0.1023,  0.0429,  0.2602,  0.0689, -0.0318,  0.2586],\n",
      "        [-0.3033, -0.0364,  0.0636, -0.0470, -0.0575,  0.0904, -0.0063, -0.0385],\n",
      "        [-0.4173,  0.0205, -0.2377, -0.0165, -0.1277,  0.1231,  0.0827, -0.0319],\n",
      "        [-0.0946, -0.0222,  0.2705, -0.1702,  0.0166,  0.0230, -0.0219,  0.1077]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "X = torch.rand(size=(8, 8))\n",
    "print(comp_conv2d(conv2d, X))\n",
    "print(comp_conv2d(conv2d, X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e6e41-6bae-455a-a77d-1493b77b6503",
   "metadata": {},
   "source": [
    "## 步幅\n",
    "\n",
    "在计算互相关时，卷积窗口从输入张量的左上角开始，向下、向右滑动。\n",
    "在前面的例子中，我们默认每次滑动一个元素。\n",
    "但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。\n",
    "\n",
    "我们将每次滑动元素的数量称为*步幅*（stride）。到目前为止，我们只使用过高度或宽度为$1$的步幅，那么如何使用较大的步幅呢？\n",
    " :numref:`img_conv_stride`是垂直步幅为$3$，水平步幅为$2$的二维互相关运算。\n",
    "着色部分是输出元素以及用于输出计算的输入和内核张量元素：$0\\times0+0\\times1+1\\times2+2\\times3=8$、$0\\times0+6\\times1+0\\times2+0\\times3=6$。\n",
    "\n",
    "可以看到，为了计算输出中第一列的第二个元素和第一行的第二个元素，卷积窗口分别向下滑动三行和向右滑动两列。但是，当卷积窗口继续向右滑动两列时，没有输出，因为输入元素无法填充窗口（除非我们添加另一列填充）。\n",
    "\n",
    "![垂直步幅为 $3$，水平步幅为 $2$ 的二维互相关运算。](https://zh.d2l.ai/_images/conv-stride.svg)\n",
    ":label:`img_conv_stride`\n",
    "\n",
    "通常，当垂直步幅为$s_h$、水平步幅为$s_w$时，输出形状为\n",
    "\n",
    "$$\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor \\times \\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor.$$\n",
    "\n",
    "如果我们设置了$p_h=k_h-1$和$p_w=k_w-1$，则输出形状将简化为$\\lfloor(n_h+s_h-1)/s_h\\rfloor \\times \\lfloor(n_w+s_w-1)/s_w\\rfloor$。\n",
    "更进一步，如果输入的高度和宽度可以被垂直和水平步幅整除，则输出形状将为$(n_h/s_h) \\times (n_w/s_w)$。\n",
    "\n",
    "下面，我们[**将高度和宽度的步幅设置为2**]，从而将输入的高度和宽度减半。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "196a02dc-cbcd-405b-9950-89d7cf57abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[-0.6603, -0.5337, -0.6400, -0.5630],\n",
      "        [-0.5202, -0.8331, -0.6707, -0.5979],\n",
      "        [-0.5222, -0.6569, -0.8150, -0.6744],\n",
      "        [-0.7237, -0.5718, -0.4855, -0.6304]], grad_fn=<ReshapeAliasBackward0>)\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "# this means kernel is of size (3, 3) padding = 1(1, 1) stride = 2(2, 2)\n",
    "# So the output size is: [(8-3+1+2)/2] × [(8-3+1+2)/2]\n",
    "print(comp_conv2d(conv2d, X).shape == ((8-3+1+2)/2, (8-3+1+2)/2))\n",
    "print(comp_conv2d(conv2d, X))\n",
    "print(comp_conv2d(conv2d, X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84fe38-f30f-4720-80a7-588e2a83b3c9",
   "metadata": {},
   "source": [
    "### 接下来，看**一个稍微复杂的例子**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed0c15f4-da87-467a-8db9-6b9aed1b84f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[-0.4830, -0.2295],\n",
      "        [-0.1582, -0.2536]], grad_fn=<ReshapeAliasBackward0>)\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "# this means kernel is of size (3, 5) padding = (0, 1) stride = (3, 4)\n",
    "# So the output size is: [(8-3+0+3)/3] × [(8-5+1+4)/4]\n",
    "print(comp_conv2d(conv2d, X).shape == (math.floor((8-3+0+3)/3), math.ceil((8-5+1+4)/4)))\n",
    "print(comp_conv2d(conv2d, X))\n",
    "print(comp_conv2d(conv2d, X).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c6bbc-c33d-44e1-af58-1fb6e0153680",
   "metadata": {},
   "source": [
    "为了简洁起见，当输入高度和宽度两侧的填充数量分别为$p_h$和$p_w$时，我们称之为填充$(p_h, p_w)$。当$p_h = p_w = p$时，填充是$p$。同理，当高度和宽度上的步幅分别为$s_h$和$s_w$时，我们称之为步幅$(s_h, s_w)$。特别地，当$s_h = s_w = s$时，我们称步幅为$s$。默认情况下，填充为0，步幅为1。在实践中，我们很少使用不一致的步幅或填充，也就是说，我们通常有$p_h = p_w$和$s_h = s_w$。\n",
    "\n",
    "#### 对于填充的值，我们通常会取核的维度-1，这样可以使得我们得到的输出的结果与原图片的大小一致。\n",
    "#### 虽然我们使用的是3$\\times$3的卷积核，但是随着卷积神经网络的深度增加，较深的卷积层对较浅的卷积层的感受野是很大的。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 填充可以增加输出的高度和宽度。这常用来使输出与输入具有相同的高和宽。\n",
    "* 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的$1/n$（$n$是一个大于$1$的整数）。\n",
    "* 填充和步幅可用于有效地调整数据的维度。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 对于本节中的最后一个示例，计算其输出形状，以查看它是否与实验结果一致。\n",
    "1. 在本节中的实验中，试一试其他填充和步幅组合。\n",
    "1. 对于音频信号，步幅$2$说明什么？\n",
    "1. 步幅大于$1$的计算优势是什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed70d90-0b1a-4d65-96d7-8636bd6c7f72",
   "metadata": {},
   "source": [
    "# 多输入多输出通道"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7124123-bb41-4a8b-bc89-8b7ad299f385",
   "metadata": {},
   "source": [
    "虽然我们在上面0描述了构成每个图像的多个通道和多层卷积层。例如，彩色图像具有标准的RGB通道来代表红、绿和蓝。\n",
    "但是到目前为止，我们仅展示了单个输入和单个输出通道的简化例子。\n",
    "这使得我们可以将输入、卷积核和输出看作二维张量。\n",
    "\n",
    "当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有$3\\times h\\times w$的形状。我们将这个大小为$3$的轴称为*通道*（channel）维度。本节将更深入地研究具有多输入和多输出通道的卷积核。\n",
    "\n",
    "## 多输入通道\n",
    "\n",
    "当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。假设输入的通道数为$c_i$，那么卷积核的输入通道数也需要为$c_i$。如果卷积核的窗口形状是$k_h\\times k_w$，那么当$c_i=1$时，我们可以把卷积核看作形状为$k_h\\times k_w$的二维张量。\n",
    "\n",
    "然而，当$c_i>1$时，我们卷积核的每个输入通道将包含形状为$k_h\\times k_w$的张量。将这些张量$c_i$连结在一起可以得到形状为$c_i\\times k_h\\times k_w$的卷积核。由于输入和卷积核都有$c_i$个通道，我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和（将$c_i$的结果相加）得到二维张量。这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。\n",
    "\n",
    "在下图中，我们演示了一个具有两个输入通道的二维互相关运算的示例。阴影部分是第一个输出元素以及用于计算这个输出的输入和核张量元素：$(1\\times1+2\\times2+4\\times3+5\\times4)+(0\\times0+1\\times1+3\\times2+4\\times3)=56$。\n",
    "\n",
    "![两个输入通道的互相关计算。](https://zh.d2l.ai/_images/conv-multi-in.svg)\n",
    "\n",
    "为了加深理解，我们**实现一下多输入通道互相关运算**。\n",
    "简而言之，我们所做的就是对每个通道执行互相关操作，然后将结果相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee331e07-b71c-4c58-8e79-a45e59104f33",
   "metadata": {},
   "source": [
    "<font color=\"red\">多通道最终多的通道都是图片的某一些个特征</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6302540c-36f1-4581-aab1-35fc4aab79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历“X”和“K”的第0个维度（通道维度），再把它们加在一起\n",
    "    res = torch.zeros(size=(corr2d(X[0], K[0]).shape))\n",
    "    # res = []\n",
    "    for x, k in zip(X, K):\n",
    "        # res.append(corr2d(x, k))\n",
    "        res += corr2d(x, k)\n",
    "    # return sum(res)\n",
    "    return res\n",
    "### 这里可以注意到使用torch矩阵一直相加和使用sum(List)的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c1332fa-a061-4e39-9c3e-2ef2790a2863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744e4c6-7604-4012-8682-63d8d31e1ae1",
   "metadata": {},
   "source": [
    "## 多输出通道\n",
    "\n",
    "到目前为止，不论有多少输入通道，我们还只有一个输出通道。然而，正如我们在之前所讨论过的，每一层有多个输出通道是至关重要的。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，我们可以将每个通道看作对不同特征的响应。而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。\n",
    "\n",
    "用$c_i$和$c_o$分别表示输入和输出通道的数目，并让$k_h$和$k_w$为卷积核的高度和宽度。为了获得多个通道的输出，我们可以为每个输出通道创建一个形状为$c_i\\times k_h\\times k_w$的卷积核张量，这样卷积核的形状是$c_o\\times c_i\\times k_h\\times k_w$。在互相关运算中，每个输出通道先获取所有输入通道，再以对应该输出通道的卷积核计算出结果。\n",
    "\n",
    "如下所示，我们实现一个**计算多个通道的输出的互相关函数**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db78410f-dcba-4df6-b98f-3101337ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对dim=0的list进行stack操作，相当于把所有结果放入一个空list\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    # 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。\n",
    "    # 最后将所有结果都叠加在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111ee07-973e-4c67-a72e-b8c08e6466bc",
   "metadata": {},
   "source": [
    "通过将核张量`K`与`K+1`（`K`中每个元素加$1$）和`K+2`连接起来，构造了一个具有$3$个输出通道的卷积核。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a64bf-f64f-40fe-8b91-67d877bdd852",
   "metadata": {},
   "source": [
    "下面，我们对输入张量`X`与卷积核张量`K`执行互相关运算。现在的输出包含$3$个通道，第一个通道的结果与先前输入张量`X`和多输入单输出通道的结果一致。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4987cea7-184b-4dee-ad5e-79ce5855944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, (K, K+1, K+2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0b417c-893b-4322-a981-e5a60e4be5da",
   "metadata": {},
   "source": [
    "## $1\\times 1$ 卷积层\n",
    "\n",
    "**1x1卷积**\n",
    "\n",
    "$1 \\times 1$卷积，即$k_h = k_w = 1$，看起来似乎没有多大意义。\n",
    "毕竟，卷积的本质是有效提取相邻像素间的相关特征，而$1 \\times 1$卷积显然没有此作用。\n",
    "尽管如此，$1 \\times 1$仍然十分流行，经常包含在复杂深层网络的设计中。下面，让我们详细地解读一下它的实际作用。\n",
    "\n",
    "因为使用了最小窗口，$1\\times 1$卷积失去了卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。\n",
    "其实$1\\times 1$卷积的唯一计算发生在通道上。\n",
    "\n",
    "下图展示了使用$1\\times 1$卷积核与$3$个输入通道和$2$个输出通道的互相关计算。\n",
    "这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合。\n",
    "我们可以将$1\\times 1$卷积层看作在每个像素位置应用的全连接层，以$c_i$个输入值转换为$c_o$个输出值。\n",
    "因为这仍然是一个卷积层，所以跨像素的权重是一致的。\n",
    "同时，$1\\times 1$卷积层需要的权重维度为$c_o\\times c_i$，再额外加上一个偏置。\n",
    "\n",
    "![互相关计算使用了具有3个输入通道和2个输出通道的 $1\\times 1$ 卷积核。其中，输入和输出具有相同的高度和宽度。](https://zh.d2l.ai/_images/conv-1x1.svg)\n",
    "\n",
    "下面，我们使用全连接层实现$1 \\times 1$卷积。\n",
    "请注意，我们需要对输入和输出的数据形状进行调整。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "67077642-bf59-4d73-b77e-6b78adacc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # 全连接层中的矩阵乘法\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf6ef7-a909-4141-98a1-5baa6a217078",
   "metadata": {},
   "source": [
    "当执行$1\\times 1$卷积运算时，上述函数相当于先前实现的互相关函数`corr2d_multi_in_out`。让我们用一些样本数据来验证这一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de679135-cab9-4adb-8ad7-7b392f45de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "### 这里说明(1) 直接使用卷积对其进行操作和 (2) 将K变为1×1的小核进行卷积操作得到的结果一致\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035fe56-4d8f-4f99-9bf1-97454b868d87",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 多输入多输出通道可以用来扩展卷积层的模型。\n",
    "* 当以每像素为基础应用时，$1\\times 1$卷积层相当于全连接层。\n",
    "* $1\\times 1$卷积层通常用于调整网络层的通道数量和控制模型复杂性。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 假设我们有两个卷积核，大小分别为$k_1$和$k_2$（中间没有非线性激活函数）。\n",
    "    1. 证明运算可以用单次卷积来表示。\n",
    "    1. 这个等效的单个卷积核的维数是多少呢？\n",
    "    1. 反之亦然吗？\n",
    "1. 假设输入为$c_i\\times h\\times w$，卷积核大小为$c_o\\times c_i\\times k_h\\times k_w$，填充为$(p_h, p_w)$，步幅为$(s_h, s_w)$。\n",
    "    1. 前向传播的计算成本（乘法和加法）是多少？\n",
    "    1. 内存占用是多少？\n",
    "    1. 反向传播的内存占用是多少？\n",
    "    1. 反向传播的计算成本是多少？\n",
    "1. 如果我们将输入通道$c_i$和输出通道$c_o$的数量加倍，计算数量会增加多少？如果我们把填充数量翻一番会怎么样？\n",
    "1. 如果卷积核的高度和宽度是$k_h=k_w=1$，前向传播的计算复杂度是多少？\n",
    "1. 本节最后一个示例中的变量`Y1`和`Y2`是否完全相同？为什么？\n",
    "1. 当卷积窗口不是$1\\times 1$时，如何使用矩阵乘法实现卷积？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d0a0f4-19ca-4f49-b5ba-d02af66746c3",
   "metadata": {},
   "source": [
    "# 汇聚层\n",
    "\n",
    "通常当我们处理图像时，我们希望逐渐降低隐藏表示的空间分辨率、聚集信息，这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大。\n",
    "\n",
    "而我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”），所以我们最后一层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。\n",
    "\n",
    "此外，当检测较底层的特征时（例如在上面讨论的边缘），我们通常希望这些特征保持某种程度上的平移不变性。例如，如果我们拍摄黑白之间轮廓清晰的图像`X`，并将整个图像向右移动一个像素，即`Z[i, j] = X[i, j + 1]`，则新图像`Z`的输出可能大不相同。而在现实中，随着拍摄角度的移动，任何物体几乎不可能发生在同一像素上。即使用三脚架拍摄一个静止的物体，由于快门的移动而引起的相机振动，可能会使所有物体左右移动一个像素（除了高端相机配备了特殊功能来解决这个问题）。\n",
    "\n",
    "本节将介绍*汇聚*（pooling）层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。\n",
    "\n",
    "## 最大汇聚层和平均汇聚层\n",
    "\n",
    "与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（有时称为*汇聚窗口*）遍历的每个位置计算一个输出。\n",
    "然而，不同于卷积层中的输入与卷积核之间的互相关计算，汇聚层不包含参数。\n",
    "相反，池运算是确定性的，我们通常计算汇聚窗口中所有元素的最大值或平均值。这些操作分别称为*最大汇聚层*（maximum pooling）和*平均汇聚层*（average pooling）。\n",
    "\n",
    "在这两种情况下，与互相关运算符一样，汇聚窗口从输入张量的左上角开始，从左往右、从上往下的在输入张量内滑动。在汇聚窗口到达的每个位置，它计算该窗口中输入子张量的最大值或平均值。计算最大值或平均值是取决于使用了最大汇聚层还是平均汇聚层。\n",
    "\n",
    "![汇聚窗口形状为 $2\\times 2$ 的最大汇聚层。着色部分是第一个输出元素，以及用于计算这个输出的输入元素: $\\max(0, 1, 3, 4)=4$.](http://d2l.ai/_images/pooling.svg)\n",
    "\n",
    "图中的输出张量的高度为$2$，宽度为$2$。这四个元素为每个汇聚窗口中的最大值：\n",
    "\n",
    "$$\n",
    "\\max(0, 1, 3, 4)=4,\\\\\n",
    "\\max(1, 2, 4, 5)=5,\\\\\n",
    "\\max(3, 4, 6, 7)=7,\\\\\n",
    "\\max(4, 5, 7, 8)=8.\\\\\n",
    "$$\n",
    "\n",
    "汇聚窗口形状为$p \\times q$的汇聚层称为$p \\times q$汇聚层，汇聚操作称为$p \\times q$汇聚。\n",
    "\n",
    "回到本节开头提到的对象边缘检测示例，现在我们将使用卷积层的输出作为$2\\times 2$最大汇聚的输入。\n",
    "设置卷积层输入为`X`，汇聚层输出为`Y`。\n",
    "无论`X[i, j]`和`X[i, j + 1]`的值相同与否，或`X[i, j + 1]`和`X[i, j + 2]`的值相同与否，汇聚层始终输出`Y[i, j] = 1`。\n",
    "也就是说，使用$2\\times 2$最大汇聚层，即使在高度或宽度上移动一个元素，卷积层仍然可以识别到模式。\n",
    "\n",
    "在下面的代码中的`pool2d`函数，我们**实现汇聚层的前向传播**。\n",
    "这类似于之前的`corr2d`函数。\n",
    "然而，这里我们没有卷积核，输出为输入中每个区域的最大值或平均值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "72e4eabe-e313-4a45-83e0-d57e4e6ea1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size  # 这里可以把pooling层想象成一个核。这样在计算输出的结果的形状更为方便\n",
    "    out_h, out_w = (X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)\n",
    "    Y = torch.zeros((out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            if mode== \"max\":\n",
    "                Y[i, j] = torch.max(X[i:i+p_h, j:j+p_w])\n",
    "            elif mode == \"avg\":\n",
    "                Y[i, j] = torch.mean(X[i:i+p_h, j:j+p_w])\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd8bebef-de40-4119-a905-285888d98363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7455, -0.7529,  0.6861, -0.0631],\n",
       "        [-0.8431,  0.2926,  1.5933,  0.3116],\n",
       "        [-1.0706,  1.0793,  0.8551,  0.8638],\n",
       "        [ 0.2089, -0.5706, -0.2523,  1.1086]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cddcc963-9eaf-48bf-a780-bebc564c70ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7455)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3257a956-e178-466d-b32e-738a9bb854f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3245)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dcf956b5-d9fc-4140-a7f0-4feb9aca40d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d7d23-36c1-4f7a-b63e-434cb3b293c4",
   "metadata": {},
   "source": [
    "此外，我们还可以**验证平均汇聚层**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8c415f8e-02e2-477b-9e40-79ecdbd21bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), mode=\"avg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0556ed1-10da-440a-90de-0d966813ab84",
   "metadata": {},
   "source": [
    "## **填充和步幅**\n",
    "\n",
    "与卷积层一样，汇聚层也可以改变输出形状。和以前一样，我们可以通过填充和步幅以获得所需的输出形状。\n",
    "下面，我们用深度学习框架中内置的二维最大汇聚层，来演示汇聚层中填充和步幅的使用。\n",
    "我们首先构造了一个输入张量`X`，它有四个维度，其中样本数和通道数都是1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "24aa5693-8c6b-4d94-9af5-8c6089c4ef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db36711-2d68-4375-9c93-d86e61fe5d3c",
   "metadata": {},
   "source": [
    "默认情况下，**深度学习框架中的步幅与汇聚窗口的大小相同**。\n",
    "因此，如果我们使用形状为`(3, 3)`的汇聚窗口，那么默认情况下，我们得到的步幅形状为`(3, 3)`。\n",
    "\n",
    "也就是说，使用nn.MaxPool2d(size)不会有重叠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c6ec8925-9053-479f-a361-b0d003d254c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((3, 3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8949d6-25d7-4ea7-90e3-ac7d29554517",
   "metadata": {},
   "source": [
    "**填充和步幅可以手动设定**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "62329a42-ab7b-47e3-b4f6-794cadf8754a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e49ca5-5843-43ce-82fe-faa898397209",
   "metadata": {},
   "source": [
    "当然，我们可以**设定一个任意大小的矩形汇聚窗口，并分别设定填充和步幅的高度和宽度**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "68db8d24-bdca-44ac-a2ae-33dfb2d863b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f77f2c84-68a5-42d7-9a03-21f6eceb9313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "582433a0-6ddb-4cdd-8976-1f8a78796cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "901fdc83-3783-4a45-833f-08e157c11150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]],\n",
       "\n",
       "\n",
       "         [[[ 1.,  2.,  3.,  4.],\n",
       "           [ 5.,  6.,  7.,  8.],\n",
       "           [ 9., 10., 11., 12.],\n",
       "           [13., 14., 15., 16.]]]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X = torch.stack([X, X+1], dim=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c327dd94-9507-4308-a617-f8b9afc1e447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 1, 4, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05bb7d33-56f6-4d10-bde4-b4e26cc787a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape([1, 2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4a8d6f5e-a282-4c3f-a6d1-628f586ad25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 4, 4])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363fe83-0dec-4fc5-b2c5-c3b096e4e67c",
   "metadata": {},
   "source": [
    "## 多个通道\n",
    "\n",
    "在处理多通道输入数据时，**汇聚层在每个输入通道上单独运算**，而不是像卷积层一样在通道上对输入进行汇总。\n",
    "这意味着汇聚层的输出通道数与输入通道数相同。\n",
    "下面，我们将在通道维度上连结张量`X`和`X + 1`，以构建具有2个通道的输入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dadab073-454f-4358-9bee-8074ae90f9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4afc2dd-4258-4503-80b3-946ed1e6a728",
   "metadata": {},
   "source": [
    "如下所示，汇聚后输出通道的数量仍然是2。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1421836d-946d-48ee-a128-298ad7946895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8aff4-cc14-452a-80c9-815cd9fb1f98",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 对于给定输入元素，最大汇聚层会输出该窗口内的最大值，平均汇聚层会输出该窗口内的平均值。\n",
    "* 汇聚层的主要优点之一是减轻卷积层对位置的过度敏感。\n",
    "* 我们可以指定汇聚层的填充和步幅。\n",
    "* 使用最大汇聚层以及大于1的步幅，可减少空间维度（如高度和宽度）。\n",
    "* 汇聚层的输出通道数与输入通道数相同。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 尝试将平均汇聚层作为卷积层的特殊情况实现。\n",
    "1. 尝试将最大汇聚层作为卷积层的特殊情况实现。\n",
    "1. <font color=\"red\">假设汇聚层的输入大小为$c\\times h\\times w$，则汇聚窗口的形状为$p_h\\times p_w$，填充为$(p_h, p_w)$，步幅为$(s_h, s_w)$。这个汇聚层的计算成本是多少？</font>\n",
    "1. 为什么最大汇聚层和平均汇聚层的工作方式不同？\n",
    "1. 我们是否需要最小汇聚层？可以用已知函数替换它吗？\n",
    "1. 除了平均汇聚层和最大汇聚层，是否有其它函数可以考虑（提示：回想一下`softmax`）？为什么它不流行？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "77914465-bfc4-4b82-ac46-384621ececb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.rand(size=(10, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bb465568-0a2e-40c9-9d8b-2f71ba16c014",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "85ce77f6-9896-401c-a023-780908dec381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0879, 0.0830, 0.1159, 0.1438, 0.0645, 0.0909, 0.1013, 0.1190, 0.1060,\n",
       "        0.0878])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0b8b9-76c7-4b2f-bbcf-08d11bc441b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
